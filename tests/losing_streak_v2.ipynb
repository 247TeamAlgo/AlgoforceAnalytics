{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3afa2f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5dc32775",
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_DSN: str = os.getenv(\n",
    "    \"TRADES_DSN\",\n",
    "    \"mysql+mysqldb://247team:password@192.168.50.238:3306/trades\",\n",
    ")\n",
    "engine = sa.create_engine(MYSQL_DSN, pool_pre_ping=True)\n",
    "\n",
    "def read_account_trades(account: str, start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return trades in [start, end], realizedPnl net of commission, indexed by 'time'.\n",
    "    \"\"\"\n",
    "    sql = (\n",
    "        \"SELECT symbol, id, orderId, side, price, qty, realizedPnl, commission, time, positionSide \"\n",
    "        f\"FROM `{account}` WHERE time >= :start AND time <= :end\"\n",
    "    )\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql_query(text(sql), conn, params={\"start\": start, \"end\": end})\n",
    "\n",
    "    if df.empty:\n",
    "        idx = pd.DatetimeIndex([], name=\"time\")\n",
    "        return pd.DataFrame(\n",
    "            columns=[\"symbol\",\"id\",\"orderId\",\"side\",\"price\",\"qty\",\"realizedPnl\",\"commission\",\"positionSide\",\"account\",],\n",
    "            index=idx,\n",
    "        )\n",
    "\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"time\"]).sort_values(\"time\").set_index(\"time\")\n",
    "\n",
    "    # numeric coercions\n",
    "    for col in (\"realizedPnl\", \"commission\"):\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # net realized after commission\n",
    "    df[\"realizedPnl\"] = df[\"realizedPnl\"] - df[\"commission\"]\n",
    "    df[\"account\"] = account\n",
    "    df.to_csv(\"fund2_losingstreak.csv\", index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a1d291fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realizedpnl_daily_sum(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    day_start_hour: int = 8,\n",
    ") -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"date_from_8am\", \"daily_realizedpnl\"])\n",
    "\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df = df.copy()\n",
    "        df.index = pd.to_datetime(df.index, errors=\"coerce\")\n",
    "\n",
    "    if \"realizedPnl\" not in df.columns:\n",
    "        raise KeyError(\"Input DataFrame must have a 'realizedPnl' column.\")\n",
    "\n",
    "    shifted = df.copy()\n",
    "    shifted.index = shifted.index - pd.Timedelta(hours=day_start_hour)\n",
    "\n",
    "    daily = (\n",
    "        shifted[\"realizedPnl\"]\n",
    "        .groupby(shifted.index.date)\n",
    "        .sum()\n",
    "        .rename(\"daily_realizedpnl\")          # column name for the values\n",
    "        .rename_axis(\"date_from_8am\")         # name the date index\n",
    "        .reset_index()                        # -> DataFrame with the two columns\n",
    "    )\n",
    "    return daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b3216ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_neg_streak(df: pd.DataFrame, include_zero: bool = False) -> int:\n",
    "    streak = max_streak = 0\n",
    "    values = df[\"daily_realizedpnl\"]\n",
    "    for v in values:\n",
    "        is_neg = (v <= 0) if include_zero else (v < 0)\n",
    "        streak = streak + 1 if is_neg else 0\n",
    "        if streak > max_streak:\n",
    "            max_streak = streak\n",
    "    return max_streak "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "60fddf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily pnl =\n",
      "   date_from_8am  daily_realizedpnl\n",
      "24    2025-09-28           4.204324\n",
      "23    2025-09-27        2035.883460\n",
      "22    2025-09-26         165.383059\n",
      "21    2025-09-25         499.766354\n",
      "20    2025-09-23         -49.069193\n",
      "19    2025-09-22        -870.740311\n",
      "18    2025-09-21         -13.622879\n",
      "17    2025-09-20       -1157.765395\n",
      "16    2025-09-19         482.644241\n",
      "15    2025-09-18       -4310.758043\n",
      "14    2025-09-17        -385.308098\n",
      "13    2025-09-16       -1368.987969\n",
      "12    2025-09-15        1881.691413\n",
      "11    2025-09-14         175.806000\n",
      "10    2025-09-13       -1159.610581\n",
      "9     2025-09-12         -10.739574\n",
      "8     2025-09-09         575.245467\n",
      "7     2025-09-08         -40.530488\n",
      "6     2025-09-07         117.629933\n",
      "5     2025-09-06         -37.907604\n",
      "4     2025-09-05         -34.150034\n",
      "3     2025-09-04           0.290872\n",
      "2     2025-09-03         176.631605\n",
      "1     2025-09-02         479.278267\n",
      "0     2025-09-01        -215.236770\n",
      "Max loss streak = 4\n"
     ]
    }
   ],
   "source": [
    "acct_trades = read_account_trades(\n",
    "    account=\"algoforce1\",\n",
    "    start=\"2025-09-01T00:00:00\",\n",
    "    end=\"2025-09-29 12:00:28\",\n",
    ")\n",
    "\n",
    "daily_pnl = realizedpnl_daily_sum(acct_trades)\n",
    "daily_pnl = daily_pnl.iloc[::-1].copy() # Reverse sort for testing the tallying only\n",
    "print(f\"Daily pnl =\\n{daily_pnl}\")\n",
    "\n",
    "result = max_neg_streak(daily_pnl)\n",
    "print(f\"Max loss streak = {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fb81ea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily (API-parity) =\n",
      "           day     net_pnl\n",
      "0  2025-10-01 -122.114010\n",
      "1  2025-10-02 -306.376177\n",
      "2  2025-10-03   -3.724823\n",
      "3  2025-10-04    0.000000\n",
      "4  2025-10-05    0.000000\n",
      "Max loss streak (strict negative) = 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "\n",
    "MYSQL_DSN: str = os.getenv(\n",
    "    \"TRADES_DSN\",\n",
    "    \"mysql+mysqldb://247team:password@192.168.50.238:3306/trades\",\n",
    ")\n",
    "engine = sa.create_engine(MYSQL_DSN, pool_pre_ping=True)\n",
    "\n",
    "def read_account_trades(account: str, start_dt: str, end_dt: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return trades in [start_dt, end_dt], with realizedPnl net of commission.\n",
    "    Index is a pandas.DatetimeIndex on 'time'.\n",
    "    start_dt/end_dt must be 'YYYY-MM-DD HH:MM:SS'.\n",
    "    \"\"\"\n",
    "    sql = (\n",
    "        \"SELECT symbol, id, orderId, side, price, qty, realizedPnl, commission, time, positionSide \"\n",
    "        f\"FROM `{account}` WHERE time >= :start AND time <= :end\"\n",
    "    )\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql_query(text(sql), conn, params={\"start\": start_dt, \"end\": end_dt})\n",
    "\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"symbol\",\"id\",\"orderId\",\"side\",\"price\",\"qty\",\n",
    "                \"realizedPnl\",\"commission\",\"positionSide\",\"account\",\n",
    "            ],\n",
    "        ).set_index(pd.DatetimeIndex([], name=\"time\"))\n",
    "\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"time\"]).sort_values(\"time\").set_index(\"time\")\n",
    "\n",
    "    # numeric coercions\n",
    "    for col in (\"realizedPnl\", \"commission\"):\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # net realized after commission (API does realized - fees)\n",
    "    df[\"realizedPnl\"] = df[\"realizedPnl\"] - df[\"commission\"]\n",
    "    df[\"account\"] = account\n",
    "    return df\n",
    "\n",
    "def daily_net_with_boundary(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    start_day: str,\n",
    "    end_day: str,\n",
    "    day_start_hour: int = 8,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replicates API bucketing:\n",
    "      - shift timestamps back by `day_start_hour`\n",
    "      - group by calendar date of the shifted index\n",
    "      - fill the full [start_day..end_day] calendar with zeros\n",
    "    Returns DataFrame with columns: ['day','gross_pnl','fees','net_pnl'] but we only compute net here.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        rng = pd.date_range(start_day, end_day, freq=\"D\")\n",
    "        return pd.DataFrame({\"day\": rng.strftime(\"%Y-%m-%d\"), \"net_pnl\": 0.0})\n",
    "\n",
    "    # Work on a copy; shift time boundary like the API\n",
    "    shifted = df.copy()\n",
    "    shifted.index = shifted.index - pd.Timedelta(hours=day_start_hour)\n",
    "\n",
    "    # Sum net by shifted calendar date\n",
    "    # (we only have net; gross/fees breakdown isnâ€™t needed for streak)\n",
    "    grouped = (\n",
    "        shifted[\"realizedPnl\"]\n",
    "        .groupby(shifted.index.date)\n",
    "        .sum()\n",
    "        .rename(\"net_pnl\")\n",
    "        .rename_axis(\"day\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    # Normalize day to ISO strings\n",
    "    grouped[\"day\"] = pd.to_datetime(grouped[\"day\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Fill the full calendar with 0s like buildDailySeries\n",
    "    full = pd.DataFrame(\n",
    "        {\"day\": pd.date_range(start_day, end_day, freq=\"D\").strftime(\"%Y-%m-%d\")}\n",
    "    )\n",
    "    daily = full.merge(grouped, on=\"day\", how=\"left\")\n",
    "    daily[\"net_pnl\"] = daily[\"net_pnl\"].fillna(0.0).astype(float)\n",
    "\n",
    "    return daily[[\"day\", \"net_pnl\"]]\n",
    "\n",
    "def max_consecutive_losses(daily: pd.DataFrame, *, include_zero: bool = False) -> int:\n",
    "    \"\"\"\n",
    "    Matches API semantics when include_zero=False: strictly negative only.\n",
    "    Expects 'daily' with a 'net_pnl' column in chronological order and\n",
    "    full calendar (zeros on no-trade days).\n",
    "    \"\"\"\n",
    "    max_streak = 0\n",
    "    streak = 0\n",
    "    for v in daily[\"net_pnl\"].tolist():\n",
    "        is_loss = (v <= 0.0) if include_zero else (v < 0.0)\n",
    "        if is_loss:\n",
    "            streak += 1\n",
    "            if streak > max_streak:\n",
    "                max_streak = streak\n",
    "        else:\n",
    "            streak = 0\n",
    "    return max_streak\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use the SAME window as your API call\n",
    "    start_day = \"2025-10-01\"\n",
    "    end_day = \"2025-10-05\"\n",
    "    account = \"fund3\"\n",
    "\n",
    "    # Query bounds for SQL must span the full days. Since we shift by 8h before grouping,\n",
    "    # keep it simple and just fetch the entire [00:00..23:59:59] window in DB local time.\n",
    "    acct_trades = read_account_trades(\n",
    "        account=account,\n",
    "        start_dt=f\"{start_day} 00:00:00\",\n",
    "        end_dt=f\"{end_day} 23:59:59\",\n",
    "    )\n",
    "\n",
    "    daily = daily_net_with_boundary(\n",
    "        acct_trades,\n",
    "        start_day=start_day,\n",
    "        end_day=end_day,\n",
    "        day_start_hour=8,  # CRITICAL: match API when you pass &dayStartHour=8\n",
    "    )\n",
    "    daily.to_csv(f\"{account}_daily.csv\",index=True)\n",
    "\n",
    "    # Compute strict-negative streak like the API\n",
    "    max_loss_streak = max_consecutive_losses(daily, include_zero=False)\n",
    "\n",
    "    print(\"Daily (API-parity) =\\n\", daily)\n",
    "    print(f\"Max loss streak (strict negative) = {max_loss_streak}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afmonitor2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
