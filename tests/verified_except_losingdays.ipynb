{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cdc43a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "import redis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6cc67f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "\n",
    "# Selected accounts\n",
    "ACCOUNTS: List[str] = [\"fund2\", \"fund3\"]\n",
    "\n",
    "# Legacy date range defaults\n",
    "START_DATE: str = \"2025-09-01\"\n",
    "END_DATE: str = pd.Timestamp.today().normalize().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Cash baselines\n",
    "INITIAL_BALANCE: Dict[str, float] = {\n",
    "    \"mirrorx1\": 78171.45,\n",
    "    \"mirrorx2\": 78879.04,\n",
    "    \"mirrorx3\": 94077.01,\n",
    "    \"mirrorx4\": 93032.39,\n",
    "    \"team\": 94856.10,\n",
    "    \"office\": 66293.43,\n",
    "    \"algoforce1\": 96663.75,\n",
    "    \"algoforce5\": 66464.70,\n",
    "    \"fund2\": 46544.94,\n",
    "    \"fund3\": 47669.61,\n",
    "}\n",
    "WITHDRAWAL: Dict[str, float] = {\n",
    "    \"mirrorx1\": 3500.0,\n",
    "    \"mirrorx2\": 3500.0,\n",
    "    \"mirrorx3\": 3500.0,\n",
    "    \"mirrorx4\": 3500.0,\n",
    "    \"team\": 3500.0,\n",
    "    \"office\": 1500.0,\n",
    "    \"algoforce1\": 3500.0,\n",
    "    \"algoforce5\": 1500.0,\n",
    "    \"fund2\": 0.0,\n",
    "    \"fund3\": 0.0,\n",
    "}\n",
    "PREVIOUS_PNL: Dict[str, float] = {\n",
    "    \"mirrorx1\": 0.0,\n",
    "    \"mirrorx2\": 0.0,\n",
    "    \"mirrorx3\": 0.0,\n",
    "    \"mirrorx4\": 0.0,\n",
    "    \"team\": 0.0,\n",
    "    \"office\": 0.0,\n",
    "    \"algoforce1\": 0.0,\n",
    "    \"algoforce5\": 0.0,\n",
    "    \"fund2\": 0.0,\n",
    "    \"fund3\": 0.0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f1e37454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sources\n",
    "MYSQL_DSN: str = os.getenv(\n",
    "    \"TRADES_DSN\",\n",
    "    \"mysql+mysqldb://247team:password@192.168.50.238:3306/trades\",\n",
    ")\n",
    "REDIS_HOST: str = os.getenv(\"REDIS_HOST\", \"localhost\")\n",
    "REDIS_PORT: int = int(os.getenv(\"REDIS_PORT\", \"6379\"))\n",
    "\n",
    "# Engines/clients\n",
    "engine = sa.create_engine(MYSQL_DSN, pool_pre_ping=True)\n",
    "r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aec690de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# REDIS HELPERS\n",
    "# =========================\n",
    "\n",
    "def get_redis_json(key: str) -> Optional[object]:\n",
    "    raw = r.get(key)\n",
    "    if not raw:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(raw)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_tradesheet_pair_map(account: str) -> Dict[int, str]:\n",
    "    \"\"\"\n",
    "    Build mapping: orderId (int) -> pair (str) from Redis {account}_tradesheet.\n",
    "    Accepts payload as list[dict] or {\"rows\": [...]} / {\"data\": [...]} shapes.\n",
    "    Uses entry_order_0/1 and exit_order_0/1.\n",
    "    \"\"\"\n",
    "    key = f\"{account}_tradesheet\"\n",
    "    data = get_redis_json(key)\n",
    "    mapping: Dict[int, str] = {}\n",
    "    if not data:\n",
    "        return mapping\n",
    "\n",
    "    rows: List[dict]\n",
    "    if isinstance(data, list):\n",
    "        rows = data\n",
    "    elif isinstance(data, dict):\n",
    "        rows = data.get(\"rows\") or data.get(\"data\") or []\n",
    "        if not isinstance(rows, list):\n",
    "            rows = []\n",
    "    else:\n",
    "        rows = []\n",
    "\n",
    "    for row in rows:\n",
    "        pair = (row.get(\"pair\") or row.get(\"PAIR\") or \"\").strip()\n",
    "        if not pair:\n",
    "            continue\n",
    "        for col in (\"entry_order_0\", \"entry_order_1\", \"exit_order_0\", \"exit_order_1\"):\n",
    "            oid_val = row.get(col)\n",
    "            if oid_val in (None, \"\"):\n",
    "                continue\n",
    "            try:\n",
    "                mapping[int(oid_val)] = pair\n",
    "            except Exception:\n",
    "                # tolerate non-integer junk silently\n",
    "                continue\n",
    "\n",
    "    return mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d07de5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SQL & METRIC HELPERS\n",
    "# =========================\n",
    "\n",
    "def read_account_trades(account: str, start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return trades in [start, end], realizedPnl net of commission, indexed by 'time'.\n",
    "    \"\"\"\n",
    "    sql = (\n",
    "        \"SELECT symbol, id, orderId, side, price, qty, realizedPnl, commission, time, positionSide \"\n",
    "        f\"FROM `{account}` WHERE time >= :start AND time <= :end\"\n",
    "    )\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql_query(text(sql), conn, params={\"start\": start, \"end\": end})\n",
    "\n",
    "    if df.empty:\n",
    "        idx = pd.DatetimeIndex([], name=\"time\")\n",
    "        return pd.DataFrame(\n",
    "            columns=[\n",
    "                \"symbol\",\n",
    "                \"id\",\n",
    "                \"orderId\",\n",
    "                \"side\",\n",
    "                \"price\",\n",
    "                \"qty\",\n",
    "                \"realizedPnl\",\n",
    "                \"commission\",\n",
    "                \"positionSide\",\n",
    "                \"account\",\n",
    "            ],\n",
    "            index=idx,\n",
    "        )\n",
    "\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"time\"]).sort_values(\"time\").set_index(\"time\")\n",
    "\n",
    "    # numeric coercions\n",
    "    for col in (\"realizedPnl\", \"commission\"):\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    # net realized after commission\n",
    "    df[\"realizedPnl\"] = df[\"realizedPnl\"] - df[\"commission\"]\n",
    "    df[\"account\"] = account\n",
    "    return df\n",
    "\n",
    "\n",
    "def wallet_upnl(account: str) -> float:\n",
    "    \"\"\"\n",
    "    Sum unrealizedProfit from Redis {account}_live. Returns 0.0 on missing/invalid.\n",
    "    \"\"\"\n",
    "    data = get_redis_json(f\"{account}_live\")\n",
    "    if not data:\n",
    "        return 0.0\n",
    "    df = pd.DataFrame(data)\n",
    "    if df.empty or \"unrealizedProfit\" not in df.columns:\n",
    "        return 0.0\n",
    "    return pd.to_numeric(df[\"unrealizedProfit\"], errors=\"coerce\").fillna(0.0).sum()\n",
    "\n",
    "\n",
    "def daily_pnl_modern(df: pd.DataFrame, start: str, end: str, upnl_today: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Modern daily series: full calendar reindex [start..end], UPNL applied on END_DATE only.\n",
    "    Used for drawdown (more stable).\n",
    "    \"\"\"\n",
    "    start_ts = pd.Timestamp(start).normalize()\n",
    "    end_ts = pd.Timestamp(end).normalize()\n",
    "    idx = pd.date_range(start_ts, end_ts, freq=\"D\")\n",
    "\n",
    "    if df.empty:\n",
    "        d = pd.DataFrame(index=idx, data={\"pnl\": 0.0})\n",
    "    else:\n",
    "        d = df.groupby(pd.Grouper(freq=\"D\"))[\"realizedPnl\"].sum().to_frame(\"pnl\")\n",
    "        d = d.reindex(idx, fill_value=0.0)\n",
    "\n",
    "    d.loc[end_ts, \"pnl\"] += float(upnl_today)\n",
    "    return d\n",
    "\n",
    "\n",
    "def monthly_max_drawdown_from_equity(daily_equity: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Per-month max drawdown (negative fraction), based on daily equity.\n",
    "    \"\"\"\n",
    "    def _mdd(frame: pd.DataFrame) -> float:\n",
    "        rb = frame[\"running_bal\"]\n",
    "        peaks = rb.cummax()\n",
    "        dd = (rb - peaks) / peaks.replace(0.0, np.nan)\n",
    "        return float(dd.min()) if len(dd) else 0.0\n",
    "\n",
    "    df = daily_equity.to_frame(\"running_bal\")\n",
    "    out = df.groupby(pd.Grouper(freq=\"ME\")).apply(_mdd)\n",
    "    out.index.name = \"MonthEnd\"\n",
    "    return out\n",
    "\n",
    "\n",
    "def daily_pnl_legacy(df: pd.DataFrame, upnl_today: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    LEGACY daily series:\n",
    "    - Group only existing rows by day (no calendar reindex).\n",
    "    - Apply UPNL to the *last* daily row (not necessarily today).\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"pnl\"])\n",
    "    d = df.groupby(pd.Grouper(freq=\"D\"))[\"realizedPnl\"].sum().to_frame(\"pnl\")\n",
    "    d.iloc[-1, d.columns.get_loc(\"pnl\")] += float(upnl_today)\n",
    "    return d\n",
    "\n",
    "\n",
    "def monthly_return_from_equity_legacy(daily_equity: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    LEGACY monthly returns: (last - first) / first using only present daily rows.\n",
    "    \"\"\"\n",
    "    rb = daily_equity.to_frame(\"running_bal\")\n",
    "    agg = rb.groupby(pd.Grouper(freq=\"ME\"))[\"running_bal\"].agg([\"first\", \"last\"])\n",
    "    out = (agg[\"last\"] - agg[\"first\"]) / agg[\"first\"].replace(0.0, np.nan)\n",
    "    out.name = \"return\"\n",
    "    return out.fillna(0.0)\n",
    "\n",
    "\n",
    "def losing_streaks(daily_pnl: pd.Series) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    (current_streak, max_streak) of strictly negative daily PnL.\n",
    "    \"\"\"\n",
    "    loss_flags = (daily_pnl < 0).astype(int).tolist()\n",
    "\n",
    "    max_streak = 0\n",
    "    cur = 0\n",
    "    for v in loss_flags:\n",
    "        cur = cur + 1 if v else 0\n",
    "        if cur > max_streak:\n",
    "            max_streak = cur\n",
    "\n",
    "    cur_streak = 0\n",
    "    for v in reversed(loss_flags):\n",
    "        if v:\n",
    "            cur_streak += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return int(cur_streak), int(max_streak)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2ac8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PIPELINE\n",
    "# =========================\n",
    "\n",
    "raw_trades: List[pd.DataFrame] = []\n",
    "per_account_daily_modern: Dict[str, pd.DataFrame] = {}\n",
    "per_account_equity_modern: Dict[str, pd.Series] = {}\n",
    "per_account_monthly_dd: Dict[str, pd.Series] = {}\n",
    "\n",
    "per_account_monthly_ret: Dict[str, pd.Series] = {}\n",
    "per_account_losing: Dict[str, Tuple[int, int]] = {}\n",
    "\n",
    "for acc in ACCOUNTS:\n",
    "    init_equity = INITIAL_BALANCE[acc] - WITHDRAWAL[acc] + PREVIOUS_PNL[acc]\n",
    "\n",
    "    # SQL trades for date range\n",
    "    trades = read_account_trades(acc, START_DATE, END_DATE)\n",
    "\n",
    "    # Accurate pair attribution from Redis tradesheet\n",
    "    pair_map = load_tradesheet_pair_map(acc)\n",
    "    if trades.empty:\n",
    "        trades[\"pair\"] = pd.Series(dtype=str)\n",
    "    else:\n",
    "        # orderId in SQL is bigint; cast to Int64 then map\n",
    "        oid = pd.to_numeric(trades[\"orderId\"], errors=\"coerce\").astype(\"Int64\")\n",
    "        trades[\"pair\"] = oid.map(lambda x: pair_map.get(int(x)) if x is not pd.NA else None)\n",
    "        trades[\"pair\"] = trades[\"pair\"].fillna(\"UNMAPPED\")\n",
    "\n",
    "    # Live UPNL\n",
    "    upnl = wallet_upnl(acc)\n",
    "\n",
    "    # Modern series → drawdown\n",
    "    d_modern = daily_pnl_modern(trades, START_DATE, END_DATE, upnl_today=upnl)\n",
    "    eq_modern = d_modern[\"pnl\"].cumsum() + init_equity\n",
    "    per_account_daily_modern[acc] = d_modern\n",
    "    per_account_equity_modern[acc] = eq_modern\n",
    "    per_account_monthly_dd[acc] = monthly_max_drawdown_from_equity(eq_modern)\n",
    "\n",
    "    # Legacy series → returns (exact legacy parity)\n",
    "    d_legacy = daily_pnl_legacy(trades, upnl_today=upnl)\n",
    "    if d_legacy.empty:\n",
    "        per_account_monthly_ret[acc] = pd.Series(dtype=float, name=\"return\")\n",
    "    else:\n",
    "        eq_legacy = d_legacy[\"pnl\"].cumsum() + init_equity\n",
    "        per_account_monthly_ret[acc] = monthly_return_from_equity_legacy(eq_legacy)\n",
    "\n",
    "    # Losing streaks computed on daily PnL; use modern calendarized days for stability\n",
    "    per_account_losing[acc] = losing_streaks(d_modern[\"pnl\"])\n",
    "\n",
    "    raw_trades.append(trades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a84ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined portfolio (modern) for drawdown\n",
    "daily_frames_modern = [df.rename(columns={\"pnl\": acc}) for acc, df in per_account_daily_modern.items()]\n",
    "combined_daily_modern = pd.concat(daily_frames_modern, axis=1).fillna(0.0) if daily_frames_modern else pd.DataFrame()\n",
    "if not combined_daily_modern.empty:\n",
    "    combined_daily_modern[\"pnl\"] = combined_daily_modern.sum(axis=1)\n",
    "    portfolio_init = sum(INITIAL_BALANCE[a] - WITHDRAWAL[a] + PREVIOUS_PNL[a] for a in ACCOUNTS)\n",
    "    combined_daily_modern[\"running_bal\"] = combined_daily_modern[\"pnl\"].cumsum() + portfolio_init\n",
    "    combined_monthly_dd = monthly_max_drawdown_from_equity(combined_daily_modern[\"running_bal\"])\n",
    "else:\n",
    "    combined_monthly_dd = pd.Series(dtype=float, name=\"return\")\n",
    "\n",
    "# Combined portfolio (legacy) for returns\n",
    "legacy_daily_frames = []\n",
    "for acc in ACCOUNTS:\n",
    "    # reconstruct the same legacy d_legacy to avoid double Redis hits:\n",
    "    # safer to recompute since wallet_upnl() is quick; or pass cached values if you prefer.\n",
    "    trades = read_account_trades(acc, START_DATE, END_DATE)\n",
    "    upnl = wallet_upnl(acc)\n",
    "    d_legacy = daily_pnl_legacy(trades, upnl_today=upnl)\n",
    "    if not d_legacy.empty:\n",
    "        legacy_daily_frames.append(d_legacy.rename(columns={\"pnl\": acc}))\n",
    "\n",
    "if legacy_daily_frames:\n",
    "    combined_legacy = pd.concat(legacy_daily_frames, axis=1).fillna(0.0)\n",
    "    combined_legacy[\"pnl\"] = combined_legacy.sum(axis=1)\n",
    "    portfolio_init = sum(INITIAL_BALANCE[a] - WITHDRAWAL[a] + PREVIOUS_PNL[a] for a in ACCOUNTS)\n",
    "    combined_legacy[\"running_bal\"] = combined_legacy[\"pnl\"].cumsum() + portfolio_init\n",
    "    combined_monthly_ret = monthly_return_from_equity_legacy(combined_legacy[\"running_bal\"])\n",
    "else:\n",
    "    combined_monthly_ret = pd.Series(dtype=float, name=\"return\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# TABULAR OUTPUTS\n",
    "# =========================\n",
    "\n",
    "# 1) Monthly Max Drawdown (per-account + combined) — modern method\n",
    "drawdown = pd.concat(\n",
    "    [pd.Series(v, name=acc.upper()) for acc, v in per_account_monthly_dd.items()]\n",
    "    + [pd.Series(combined_monthly_dd, name=\"COMBINED\")],\n",
    "    axis=1,\n",
    ")\n",
    "drawdown.index = drawdown.index.strftime(\"%b-%Y\")\n",
    "drawdown.index.name = \"Month\"\n",
    "\n",
    "# 2) Monthly Returns (per-account + combined) — LEGACY method\n",
    "rets = pd.concat(\n",
    "    [pd.Series(v, name=acc.upper()) for acc, v in per_account_monthly_ret.items()]\n",
    "    + [pd.Series(combined_monthly_ret, name=\"COMBINED\")],\n",
    "    axis=1,\n",
    ")\n",
    "rets.index = rets.index.strftime(\"%b-%Y\")\n",
    "rets.index.name = \"Month\"\n",
    "\n",
    "# 3) Consecutive Losing Days (current, max)\n",
    "consecutive_losing = pd.DataFrame(\n",
    "    {acc.upper(): {\"current\": c, \"max\": m} for acc, (c, m) in per_account_losing.items()}\n",
    ").T[[\"current\", \"max\"]]\n",
    "\n",
    "# 4) Total realized PnL per SYMBOL (selected accounts + TOTAL)\n",
    "all_trades = (\n",
    "    pd.concat(raw_trades, axis=0)\n",
    "    if raw_trades\n",
    "    else pd.DataFrame(columns=[\"symbol\", \"realizedPnl\", \"account\", \"pair\"])\n",
    ")\n",
    "if all_trades.empty:\n",
    "    per_symbol = pd.DataFrame(columns=[*(acc.upper() for acc in ACCOUNTS), \"TOTAL\"])\n",
    "    per_pair = per_symbol.copy()\n",
    "else:\n",
    "    sym = (\n",
    "        all_trades.groupby([\"account\", \"symbol\"], dropna=False)[\"realizedPnl\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .pivot_table(index=\"symbol\", columns=\"account\", values=\"realizedPnl\", fill_value=0.0)\n",
    "        .reindex(columns=ACCOUNTS, fill_value=0.0)\n",
    "    )\n",
    "    sym[\"TOTAL\"] = sym.sum(axis=1)\n",
    "    sym.columns.name = None\n",
    "    per_symbol = sym\n",
    "\n",
    "    # 5) Total realized PnL per PAIR (accurate from Redis orderId->pair mapping)\n",
    "    pair_tbl = (\n",
    "        all_trades.groupby([\"account\", \"pair\"], dropna=False)[\"realizedPnl\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .pivot_table(index=\"pair\", columns=\"account\", values=\"realizedPnl\", fill_value=0.0)\n",
    "        .reindex(columns=ACCOUNTS, fill_value=0.0)\n",
    "    )\n",
    "    pair_tbl[\"TOTAL\"] = pair_tbl.sum(axis=1)\n",
    "    pair_tbl.columns.name = None\n",
    "    per_pair = pair_tbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c69bc251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Monthly return (per-account + combined)\n",
    "rets = pd.concat(\n",
    "    [pd.Series(v, name=acc.upper()) for acc, v in per_account_monthly_ret.items()] + \n",
    "    [pd.Series(combined_monthly_ret, name=\"COMBINED\")],\n",
    "    axis=1\n",
    ")\n",
    "rets.index = rets.index.strftime(\"%b-%Y\")\n",
    "rets.index.name = \"Month\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c869d7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Monthly Max Drawdown (negative fractions) ===\n",
      "            FUND2     FUND3  COMBINED\n",
      "Month                                \n",
      "Sep-2025 -0.01901 -0.021128 -0.015274\n",
      "\n",
      "=== Monthly Returns (legacy parity) ===\n",
      "             FUND2     FUND3  COMBINED\n",
      "Month                                 \n",
      "Sep-2025 -0.009309 -0.014571 -0.012323\n",
      "\n",
      "=== Consecutive Losing Days (current, max) ===\n",
      "       current  max\n",
      "FUND2        2    3\n",
      "FUND3        1    9\n",
      "\n",
      "=== Total PnL per SYMBOL (top 20 by TOTAL) ===\n",
      "               fund2        fund3        TOTAL\n",
      "symbol                                        \n",
      "APTUSDT    34.651510  1547.813557  1582.465067\n",
      "NEARUSDT   29.784175   746.366560   776.150735\n",
      "ATOMUSDT  -12.754260   455.053006   442.298747\n",
      "LTCUSDT   300.348939     0.000000   300.348939\n",
      "VETUSDT     5.482881   148.235202   153.718082\n",
      "LINKUSDT   35.902261    -1.810690    34.091571\n",
      "BTCUSDT   125.322013  -146.401019   -21.079007\n",
      "SOLUSDT   -63.195355    26.755824   -36.439531\n",
      "XRPUSDT     0.000000   -59.053797   -59.053797\n",
      "ETHUSDT   -69.432183     0.000000   -69.432183\n",
      "TRXUSDT  -145.171172     0.000000  -145.171172\n",
      "AVAXUSDT -156.727310     0.000000  -156.727310\n",
      "ADAUSDT  -264.025063    99.753084  -164.271979\n",
      "BNBUSDT  -264.625120    -1.325318  -265.950438\n",
      "UNIUSDT  -400.114660  -196.120972  -596.235633\n",
      "DOTUSDT   134.111714 -1521.911131 -1387.799417\n",
      "FILUSDT    45.993949 -1623.505085 -1577.511136\n",
      "\n",
      "=== Total PnL per PAIR (top 20 by TOTAL) ===\n",
      "               fund2      fund3        TOTAL\n",
      "pair                                        \n",
      "UNMAPPED -664.447682 -526.15078 -1190.598461\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# OPTIONAL PERSIST / DEMO\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    # Minimal demo prints. Replace with CSV/Parquet exports as you prefer.\n",
    "    pd.set_option(\"display.width\", 180)\n",
    "    pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "    print(\"\\n=== Monthly Max Drawdown (negative fractions) ===\")\n",
    "    print(drawdown.tail())\n",
    "\n",
    "    print(\"\\n=== Monthly Returns (legacy parity) ===\")\n",
    "    print(rets.tail())\n",
    "\n",
    "    print(\"\\n=== Consecutive Losing Days (current, max) ===\")\n",
    "    print(consecutive_losing)\n",
    "\n",
    "    print(\"\\n=== Total PnL per SYMBOL (top 20 by TOTAL) ===\")\n",
    "    if not per_symbol.empty:\n",
    "        print(per_symbol.sort_values(\"TOTAL\", ascending=False).head(20))\n",
    "    else:\n",
    "        print(\"(no trades)\")\n",
    "\n",
    "    print(\"\\n=== Total PnL per PAIR (top 20 by TOTAL) ===\")\n",
    "    if not per_pair.empty:\n",
    "        print(per_pair.sort_values(\"TOTAL\", ascending=False).head(20))\n",
    "    else:\n",
    "        print(\"(no trades)\")\n",
    "\n",
    "    # Example export:\n",
    "    # outdir = \"./out\"\n",
    "    # os.makedirs(outdir, exist_ok=True)\n",
    "    # drawdown.to_csv(f\"{outdir}/monthly_drawdown.csv\")\n",
    "    # rets.to_csv(f\"{outdir}/monthly_returns_legacy.csv\")\n",
    "    # consecutive_losing.to_csv(f\"{outdir}/consecutive_losing_days.csv\")\n",
    "    # per_symbol.to_csv(f\"{outdir}/total_pnl_per_symbol.csv\")\n",
    "    # per_pair.to_csv(f\"{outdir}/total_pnl_per_pair.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afmonitor2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
