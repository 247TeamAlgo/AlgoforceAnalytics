{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47f3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "import sqlalchemy as db\n",
    "import redis\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7728c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 'localhost'\n",
    "p = 6379\n",
    "r = redis.Redis(host=h, port=p)\n",
    "\n",
    "def getRedis(param):\n",
    "        try:\n",
    "            v = r.get(param)\n",
    "            val = json.loads(v)\n",
    "            return val\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "def wallet_balance(acc):\n",
    "    open_trades = getRedis(f'{acc}_live')\n",
    "    open_trades = pd.DataFrame(open_trades)\n",
    "    open_trades['unrealizedProfit'] = open_trades['unrealizedProfit'].astype(float)\n",
    "    unrealizedPnl = open_trades['unrealizedProfit'].sum()\n",
    "    return unrealizedPnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43929481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(acc, tb_name, db_name):\n",
    "    \n",
    "    if tb_name == \"trades\":\n",
    "        table_name = acc\n",
    "    else:\n",
    "        table_name = f'{acc.lower()}_{tb_name}'\n",
    "\n",
    "    try:\n",
    "        conn = db.create_engine(f'mysql+mysqldb://247team:password@192.168.50.238:3306/{db_name}')\n",
    "        query = f\"SELECT * FROM {table_name};\"\n",
    "        frame = pd.read_sql_query(text(query), conn.connect())\n",
    "        # frame = frame[['datetime', 'open', 'high', 'low', 'close', 'volume']]\n",
    "        # frame.columns = ['Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        # frame['Time'] = pd.to_datetime(frame['Time'])\n",
    "        # frame = frame.set_index('Time')\n",
    "        # frame = frame.astype(float)\n",
    "        return frame\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        raise Exception('Data is not available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c0590dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(accs):\n",
    "    \"\"\"\n",
    "    Uses the provided start_date and end_date as-is (no time normalization).\n",
    "    - Build realized equity levels (no UPNL in history).\n",
    "    - Max DD from realized levels over the window.\n",
    "    - Current DD = (last realized + TOTAL UPNL) vs realized peak (over the same window).\n",
    "    - Always emits a combined series across accounts.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    if isinstance(accs, str):\n",
    "        accs = [accs]\n",
    "\n",
    "    results = {}\n",
    "    per_account_upnl: dict[str, float] = {}\n",
    "\n",
    "    # ---------------- per-account realized level series (no UPNL in history) ----------------\n",
    "    for acc in accs:\n",
    "        balance = get_data(acc, \"balance\", \"balance\")\n",
    "        trades = get_data(acc, \"trades\", \"trades\")\n",
    "        trnsc_history = get_data(acc, \"transaction\", \"transaction_history\")\n",
    "        earnings = get_data(acc, \"earnings\", \"earnings\")\n",
    "\n",
    "        # normalize dtypes\n",
    "        balance[\"datetime\"] = pd.to_datetime(balance[\"datetime\"])\n",
    "        trades[\"time\"] = pd.to_datetime(trades[\"time\"])\n",
    "        trnsc_history[\"time\"] = pd.to_datetime(trnsc_history[\"time\"])\n",
    "        earnings[\"time\"] = pd.to_datetime(earnings[\"time\"])\n",
    "\n",
    "        # Since we're doing all time, we arbitrarily take the first date in balance as start\n",
    "        start_date = balance.iloc[0][\"datetime\"]\n",
    "        start_ts = pd.to_datetime(start_date)\n",
    "        end_ts = pd.Timestamp.now()\n",
    "        print(f\"Processing account: {acc} from {start_ts} to {end_ts}\")\n",
    "\n",
    "        # nearest realized balance at/just before start_ts\n",
    "        balance_before = balance[balance[\"datetime\"] <= start_ts]\n",
    "        if not balance_before.empty:\n",
    "            nearest_balance_val = float(balance_before.iloc[-1][\"overall_balance\"])\n",
    "            new_start_ts = pd.Timestamp(balance_before.iloc[-1][\"datetime\"])\n",
    "        else:\n",
    "            # fallback: first row in balance table\n",
    "            nearest_balance_val = float(balance.iloc[0][\"overall_balance\"])\n",
    "            new_start_ts = pd.Timestamp(balance.iloc[0][\"datetime\"])\n",
    "\n",
    "        # window the ledgers to [new_start_ts, end_ts]\n",
    "        trades_f = trades[(trades[\"time\"] >= new_start_ts) & (trades[\"time\"] <= end_ts)].copy()\n",
    "        trnsc_f = trnsc_history[(trnsc_history[\"time\"] >= new_start_ts) & (trnsc_history[\"time\"] <= end_ts)].copy()\n",
    "        earnings_f = earnings[(earnings[\"time\"] >= new_start_ts) & (earnings[\"time\"] <= end_ts)].copy()\n",
    "\n",
    "        # realized-only cash deltas (exclude transfers)\n",
    "        trades_f[\"dollar_val\"] = trades_f[\"realizedPnl\"].astype(float) - trades_f[\"commission\"].astype(float)\n",
    "        trades_f[\"transaction_type\"] = \"realizedPnl\"\n",
    "        trades_df = trades_f[[\"time\", \"dollar_val\", \"transaction_type\"]].copy()\n",
    "\n",
    "        fund = trnsc_f[trnsc_f[\"incomeType\"].str.upper() == \"FUNDING_FEE\"].copy()\n",
    "        fund[\"dollar_val\"] = fund[\"income\"].astype(float)\n",
    "        fund[\"transaction_type\"] = \"funding_fee\"\n",
    "        funding_df = fund[[\"time\", \"dollar_val\", \"transaction_type\"]].copy()\n",
    "\n",
    "        earnings_f[\"dollar_val\"] = earnings_f[\"rewards\"].astype(float)\n",
    "        earnings_f[\"transaction_type\"] = \"earnings\"\n",
    "        earnings_df = earnings_f[[\"time\", \"dollar_val\", \"transaction_type\"]].copy()\n",
    "\n",
    "        # build realized ledger (no UPNL in history)\n",
    "        ledger = pd.concat([trades_df, earnings_df, funding_df], ignore_index=True)\n",
    "        ledger = ledger.sort_values(\"time\").reset_index(drop=True)\n",
    "\n",
    "        ledger[\"running_balance\"] = nearest_balance_val + ledger[\"dollar_val\"].cumsum()\n",
    "\n",
    "        # clip the emitted series to >= start_ts (but keep new_start_ts for the baseline above)\n",
    "        ledger_final = ledger[ledger[\"time\"] >= start_ts].copy()\n",
    "        ledger_final[\"running_balance\"] = nearest_balance_val + ledger_final[\"dollar_val\"].cumsum()\n",
    "\n",
    "        # daily realized end-of-day level\n",
    "        daily_balances = ledger_final.groupby(ledger_final[\"time\"].dt.date)[\"running_balance\"].last()\n",
    "        daily_balances.index = pd.to_datetime(daily_balances.index)\n",
    "\n",
    "        # store account UPNL (used only for live current DD)\n",
    "        upnl = float(wallet_balance(acc))\n",
    "        per_account_upnl[acc] = upnl\n",
    "\n",
    "        # realized-only DD series\n",
    "        daily_returns = daily_balances.pct_change().fillna(0.0)\n",
    "        peaks = daily_balances.cummax()\n",
    "        daily_drawdowns = (daily_balances - peaks) / peaks\n",
    "\n",
    "        daily_report = pd.DataFrame({\n",
    "            \"date\": daily_balances.index,\n",
    "            \"end_balance\": daily_balances.values,\n",
    "            \"daily_return\": daily_returns.values,\n",
    "            \"daily_drawdown\": daily_drawdowns.values\n",
    "        })\n",
    "\n",
    "        # monthly aggregates (optional; from realized-only levels)\n",
    "        monthly_stats = []\n",
    "        for month, df in daily_report.groupby(pd.Grouper(key=\"date\", freq=\"ME\")):\n",
    "            if df.empty:\n",
    "                continue\n",
    "            first = float(df[\"end_balance\"].iloc[0]) if df[\"end_balance\"].iloc[0] else 0.0\n",
    "            last = float(df[\"end_balance\"].iloc[-1])\n",
    "            mret = (last / first - 1.0) if first else 0.0\n",
    "            mdd = float(df[\"daily_drawdown\"].min())\n",
    "            monthly_stats.append({\n",
    "                \"month\": month.strftime(\"%Y-%m\"),\n",
    "                \"monthly_return\": mret,\n",
    "                \"monthly_drawdown\": mdd\n",
    "            })\n",
    "        monthly_report = pd.DataFrame(monthly_stats)\n",
    "\n",
    "        results[acc] = {\"daily\": daily_report, \"monthly\": monthly_report}\n",
    "\n",
    "    # ---------------- combined (sum of realized levels) ----------------\n",
    "    combined_daily = None\n",
    "    if len(accs) >= 1:\n",
    "        per_acc_series = []\n",
    "        for acc in accs:\n",
    "            df = results[acc][\"daily\"]\n",
    "            if df.empty:\n",
    "                continue\n",
    "            per_acc_series.append(\n",
    "                df[[\"date\", \"end_balance\"]].rename(columns={\"end_balance\": f\"end_balance_{acc}\"})\n",
    "            )\n",
    "\n",
    "        if per_acc_series:\n",
    "            combined_daily = per_acc_series[0]\n",
    "            for df in per_acc_series[1:]:\n",
    "                combined_daily = pd.merge(combined_daily, df, on=\"date\", how=\"outer\")\n",
    "\n",
    "            combined_daily = combined_daily.sort_values(\"date\").reset_index(drop=True)\n",
    "            combined_daily = combined_daily.ffill()\n",
    "\n",
    "            end_cols = [c for c in combined_daily.columns if c.startswith(\"end_balance_\")]\n",
    "            combined_daily[\"end_balance_combined\"] = combined_daily[end_cols].sum(axis=1)\n",
    "\n",
    "            # realized-only DD (basis for max DD over the given window)\n",
    "            ser_realized = pd.Series(\n",
    "                combined_daily[\"end_balance_combined\"].values,\n",
    "                index=pd.to_datetime(combined_daily[\"date\"]),\n",
    "            )\n",
    "            peaks_realized = ser_realized.cummax()\n",
    "            dd_realized = (ser_realized - peaks_realized) / peaks_realized\n",
    "\n",
    "            # current (live) DD = (last_realized + TOTAL UPNL) vs realized peak\n",
    "            total_upnl = sum(per_account_upnl.get(a, 0.0) for a in accs)\n",
    "            if not ser_realized.empty:\n",
    "                last_idx = ser_realized.index[-1]\n",
    "                last_realized_val = float(ser_realized.loc[last_idx])\n",
    "                peak_val = float(peaks_realized.loc[last_idx]) if peaks_realized.loc[last_idx] else 0.0\n",
    "                current_live_dd = ((last_realized_val + total_upnl) - peak_val) / peak_val if peak_val else 0.0\n",
    "            else:\n",
    "                current_live_dd = 0.0\n",
    "\n",
    "            # output DD series: realized-only for history; last point overwritten with live current\n",
    "            dd_out = dd_realized.copy()\n",
    "            if not dd_out.empty:\n",
    "                dd_out.iloc[-1] = current_live_dd\n",
    "\n",
    "            combined_daily[\"daily_drawdown_combined\"] = dd_out.values\n",
    "\n",
    "            # monthly combined (optional)\n",
    "            monthly_stats = []\n",
    "            tmp = pd.DataFrame(\n",
    "                {\"date\": ser_realized.index, \"end_realized\": ser_realized.values, \"dd_realized\": dd_realized.values}\n",
    "            )\n",
    "            for month, df in tmp.groupby(pd.Grouper(key=\"date\", freq=\"ME\")):\n",
    "                if df.empty:\n",
    "                    continue\n",
    "                first = float(df[\"end_realized\"].iloc[0]) if df[\"end_realized\"].iloc[0] else 0.0\n",
    "                last = float(df[\"end_realized\"].iloc[-1])\n",
    "                mret = (last / first - 1.0) if first else 0.0\n",
    "                mdd = float(df[\"dd_realized\"].min())\n",
    "                monthly_stats.append({\n",
    "                    \"month\": month.strftime(\"%Y-%m\"),\n",
    "                    \"monthly_return_combined\": mret,\n",
    "                    \"monthly_drawdown_combined\": mdd\n",
    "                })\n",
    "        else:\n",
    "            combined_daily = pd.DataFrame(columns=[\"date\", \"daily_drawdown_combined\"])\n",
    "\n",
    "    return combined_daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a420986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing account: fund2 from 2025-05-01 08:02:00 to 2025-11-01 03:21:33.535256\n",
      "Processing account: fund3 from 2025-05-01 08:02:00 to 2025-11-01 03:21:37.177218\n",
      "Current Combined DD: -0.07990282153809886\n",
      "Max Combined DD: -0.08189935313710145\n"
     ]
    }
   ],
   "source": [
    "accounts = [\"fund2\", \"fund3\"]\n",
    "# start_date = \"2025-10-01 00:00:00\"\n",
    "# end_date = \"2025-10-20 00:00:00\"\n",
    "\n",
    "combined_daily = process_df(accounts)\n",
    "combined_daily.to_csv(\"combined_daily.csv\", index=False)\n",
    "current_dd = combined_daily[\"daily_drawdown_combined\"].iloc[-1] if not combined_daily.empty else None\n",
    "print(\"Current Combined DD:\", current_dd)\n",
    "max_dd = combined_daily[\"daily_drawdown_combined\"].min() if not combined_daily.empty else None\n",
    "print(\"Max Combined DD:\", max_dd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afmonitor2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
