{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b462a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql.py and config.py\n",
    "import os\n",
    "from datetime import UTC, datetime\n",
    "from functools import lru_cache\n",
    "from typing import TYPE_CHECKING, Final\n",
    "from collections.abc import Mapping\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Engine, Connection\n",
    "\n",
    "if TYPE_CHECKING:  # import only for type checking\n",
    "    from redis import Redis  # pragma: no cover\n",
    "\n",
    "DB_URL: Final[str] = os.getenv(\n",
    "    \"DB_URL\",\n",
    "    \"mysql+mysqlconnector://247team:password@192.168.50.238:3306/trades\",\n",
    ")\n",
    "\n",
    "BALANCE_SCHEMA = \"balance\"\n",
    "BALANCE_TIME_COLUMN = \"datetime\"\n",
    "BALANCE_VALUE_COLUMN = \"overall_balance\"\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_engine() -> Engine:\n",
    "    \"\"\"Return a cached SQLAlchemy Engine.\"\"\"\n",
    "    return create_engine(DB_URL, pool_pre_ping=True, pool_recycle=3600)\n",
    "\n",
    "def _sql_to_df(\n",
    "    conn: Connection, stmt: str, params: Mapping[str, object] | None = None\n",
    ") -> DataFrame:\n",
    "    \"\"\"Execute SQL and materialize a DataFrame.\"\"\"\n",
    "    q = text(stmt)\n",
    "    res = conn.execute(q, params or {})\n",
    "    try:\n",
    "        cols = list(res.keys())\n",
    "        rows = [dict(m) for m in res.mappings().all()]\n",
    "        return pd.DataFrame(rows, columns=cols)\n",
    "    finally:\n",
    "        res.close()\n",
    "\n",
    "def _coerce_float(x: object) -> float:\n",
    "    \"\"\"Robust scalar→float conversion that keeps type checkers quiet.\"\"\"\n",
    "    if isinstance(x, int | float):\n",
    "        return float(x)\n",
    "    try:\n",
    "        s = pd.Series([x])\n",
    "        v = pd.to_numeric(s, errors=\"coerce\").iloc[0]\n",
    "        return float(v) if pd.notna(v) else 0.0\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def _coerce_ts(x: object, *, default: pd.Timestamp) -> pd.Timestamp:\n",
    "    \"\"\"Coerce a single value to pd.Timestamp; fallback to provided default.\n",
    "\n",
    "    Uses a Series-based path to satisfy pandas-stubs overloads for to_datetime.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = pd.Series([x])\n",
    "        ts_series = pd.to_datetime(s, errors=\"coerce\")\n",
    "        ts0 = ts_series.iloc[0]\n",
    "        if isinstance(ts0, pd.Timestamp) and not pd.isna(ts0):\n",
    "            return ts0\n",
    "    except Exception:\n",
    "        pass\n",
    "    return default\n",
    "\n",
    "def nearest_balance_on_or_before(\n",
    "    account: str, start_ts: pd.Timestamp\n",
    ") -> tuple[float, pd.Timestamp]:\n",
    "    \"\"\"Return (balance, timestamp) for nearest snapshot <= start_ts; fallback to earliest.\"\"\"\n",
    "    eng = get_engine()\n",
    "    with eng.connect() as conn:\n",
    "        q1 = (\n",
    "            f\"SELECT `{BALANCE_TIME_COLUMN}` AS ts, `{BALANCE_VALUE_COLUMN}` AS bal \"\n",
    "            f\"FROM `{BALANCE_SCHEMA}`.`{account}_balance` \"\n",
    "            f\"WHERE `{BALANCE_TIME_COLUMN}` <= :start \"\n",
    "            f\"ORDER BY `{BALANCE_TIME_COLUMN}` DESC LIMIT 1\"\n",
    "        )\n",
    "        df = _sql_to_df(conn, q1, {\"start\": f\"{start_ts:%Y-%m-%d %H:%M:%S}\"})\n",
    "        if not df.empty:\n",
    "            bal = _coerce_float(df.at[0, \"bal\"])\n",
    "            ts = _coerce_ts(df.at[0, \"ts\"], default=start_ts)\n",
    "            return bal, ts\n",
    "\n",
    "        q2 = (\n",
    "            f\"SELECT `{BALANCE_TIME_COLUMN}` AS ts, `{BALANCE_VALUE_COLUMN}` AS bal \"\n",
    "            f\"FROM `{BALANCE_SCHEMA}`.`{account}_balance` \"\n",
    "            f\"ORDER BY `{BALANCE_TIME_COLUMN}` ASC LIMIT 1\"\n",
    "        )\n",
    "        df2 = _sql_to_df(conn, q2)\n",
    "        if df2.empty:\n",
    "            return 0.0, start_ts\n",
    "        bal2 = _coerce_float(df2.at[0, \"bal\"])\n",
    "        ts2 = _coerce_ts(df2.at[0, \"ts\"], default=start_ts)\n",
    "        return bal2, ts2\n",
    "\n",
    "def read_trades(account: str, start_dt: str, end_dt: str) -> DataFrame:\n",
    "    \"\"\"Trades with realizedPnl net of commission; index=time.\"\"\"\n",
    "    eng = get_engine()\n",
    "    sql = (\n",
    "        \"SELECT symbol, id, orderId, side, price, qty, realizedPnl, commission, time, positionSide \"\n",
    "        f\"FROM `{account}` WHERE time >= :start AND time <= :end\"\n",
    "    )\n",
    "    with eng.connect() as conn:\n",
    "        df = _sql_to_df(conn, sql, {\"start\": start_dt, \"end\": end_dt})\n",
    "    if df.empty:\n",
    "        return DataFrame(columns=[\"symbol\", \"realizedPnl\"]).set_index(\n",
    "            pd.DatetimeIndex([], name=\"time\"),\n",
    "        )\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"time\"]).set_index(\"time\").sort_index()\n",
    "    pnl = pd.to_numeric(df[\"realizedPnl\"], errors=\"coerce\").fillna(0.0)\n",
    "    fee = pd.to_numeric(df[\"commission\"], errors=\"coerce\").fillna(0.0)\n",
    "    df[\"realizedPnl\"] = pnl - fee\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_transactions(account: str, start_dt: str, end_dt: str) -> DataFrame:\n",
    "    \"\"\"Transaction history: incomeType, income, time; index=time.\"\"\"\n",
    "    eng = get_engine()\n",
    "    sql = (\n",
    "        \"SELECT incomeType, income, time \"\n",
    "        f\"FROM `transaction_history`.`{account}_transaction` \"\n",
    "        \"WHERE time >= :start AND time <= :end\"\n",
    "    )\n",
    "    with eng.connect() as conn:\n",
    "        df = _sql_to_df(conn, sql, {\"start\": start_dt, \"end\": end_dt})\n",
    "    if df.empty:\n",
    "        return DataFrame(columns=[\"incomeType\", \"income\"]).set_index(\n",
    "            pd.DatetimeIndex([], name=\"time\"),\n",
    "        )\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"time\"]).set_index(\"time\").sort_index()\n",
    "    df[\"income\"] = pd.to_numeric(df[\"income\"], errors=\"coerce\").fillna(0.0)\n",
    "    df[\"incomeType\"] = df[\"incomeType\"].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_earnings(account: str, start_dt: str, end_dt: str) -> DataFrame:\n",
    "    \"\"\"Earnings (rewards, time); index=time.\"\"\"\n",
    "    eng = get_engine()\n",
    "    sql = (\n",
    "        \"SELECT rewards, time \"\n",
    "        f\"FROM `earnings`.`{account}_earnings` \"\n",
    "        \"WHERE time >= :start AND time <= :end\"\n",
    "    )\n",
    "    with eng.connect() as conn:\n",
    "        df = _sql_to_df(conn, sql, {\"start\": start_dt, \"end\": end_dt})\n",
    "    if df.empty:\n",
    "        return DataFrame(columns=[\"rewards\"]).set_index(pd.DatetimeIndex([], name=\"time\"))\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"time\"]).set_index(\"time\").sort_index()\n",
    "    df[\"rewards\"] = pd.to_numeric(df[\"rewards\"], errors=\"coerce\").fillna(0.0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1efe0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# equity.py\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "\n",
    "def _daily_pnl(trades: DataFrame, txn: DataFrame, earn: DataFrame) -> Series:\n",
    "    \"\"\"Sum daily PnL from trades (net), funding fee, earnings. Excludes transfers.\"\"\"\n",
    "    parts: list[Series] = []\n",
    "    if not trades.empty:\n",
    "        parts.append(trades[\"realizedPnl\"])\n",
    "    if not txn.empty:\n",
    "        it = txn[\"incomeType\"].astype(str).str.upper()\n",
    "        if it.eq(\"FUNDING_FEE\").any():\n",
    "            parts.append(txn.loc[it.eq(\"FUNDING_FEE\"), \"income\"])\n",
    "        # Exclude TRANSFER by design\n",
    "    if not earn.empty:\n",
    "        parts.append(earn[\"rewards\"])\n",
    "    if not parts:\n",
    "        return pd.Series(dtype=\"float64\")\n",
    "    s = pd.concat(parts).sort_index()\n",
    "    s.index = pd.DatetimeIndex(s.index)\n",
    "    return s.resample(\"D\").sum()\n",
    "\n",
    "def build_fixed_balances(\n",
    "    accounts: list[str],\n",
    "    start_day: pd.Timestamp,\n",
    "    end_day: pd.Timestamp,\n",
    ") -> tuple[pd.DataFrame, dict[str, float]]:\n",
    "    \"\"\"Build realized equity series (no UPnL, no unrealized shift), daily frequency.\"\"\"\n",
    "    idx = pd.date_range(start_day.normalize(), end_day.normalize(), freq=\"D\")\n",
    "    cols: list[pd.Series] = []\n",
    "    init_map: dict[str, float] = {}\n",
    "\n",
    "    # Initial balance is fetched by orchestrator; here we only build deltas.\n",
    "    for acc in accounts:\n",
    "        tr = read_trades(acc, f\"{start_day.date()} 00:00:00\", f\"{end_day.date()} 23:59:59\")\n",
    "        tx = read_transactions(acc, f\"{start_day.date()} 00:00:00\", f\"{end_day.date()} 23:59:59\")\n",
    "        er = read_earnings(acc, f\"{start_day.date()} 00:00:00\", f\"{end_day.date()} 23:59:59\")\n",
    "\n",
    "        daily = _daily_pnl(tr, tx, er)\n",
    "        if daily.empty:\n",
    "            s = pd.Series(0.0, index=idx, name=acc, dtype=\"float64\")\n",
    "        else:\n",
    "            s = daily.reindex(idx).fillna(0.0).cumsum()\n",
    "        cols.append(s.rename(acc))\n",
    "\n",
    "    delta = (\n",
    "        pd.concat(cols, axis=1)\n",
    "        if cols\n",
    "        else pd.DataFrame(index=idx, columns=accounts, dtype=\"float64\")\n",
    "    )\n",
    "    return delta, init_map  # init_map kept for signature parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c056f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns.py\n",
    "def mtd_return(balance: DataFrame) -> dict[str, float]:\n",
    "    \"\"\"Month-to-date simple return per column (latest month in index).\"\"\"\n",
    "    if balance.empty:\n",
    "        return {}\n",
    "    idx = pd.DatetimeIndex(balance.index)\n",
    "    ym = idx.year * 100 + idx.month\n",
    "    latest = int(ym.max())\n",
    "    month = balance.loc[ym == latest]\n",
    "    if month.empty:\n",
    "        return {}\n",
    "    first = month.iloc[0]\n",
    "    last = month.iloc[-1]\n",
    "    out: dict[str, float] = {}\n",
    "    for col in month.columns:\n",
    "        first_val = float(first[col])\n",
    "        last_val = float(last[col])\n",
    "        out[str(col)] = (last_val - first_val) / first_val if first_val != 0.0 else 0.0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83de5914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtd_ret_realized: {'fund2': 0.014733934812096615, 'fund3': -0.031863293640260866, 'total': -0.008829522505566073}\n"
     ]
    }
   ],
   "source": [
    "# performance_metrics.py\n",
    "from typing import Sequence\n",
    "import pandas as pd\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "def _mtd_window_today() -> tuple[pd.Timestamp, pd.Timestamp, pd.Timestamp]:\n",
    "    \"\"\"Return (start_of_month_local, now_local_floored_to_hour, yesterday_local_normalized).\n",
    "\n",
    "    Anchored to Europe/Zurich. Returned timestamps are naive (tz removed) but\n",
    "    aligned to local time to match the CLI's intraday, hourly-anchored behavior.\n",
    "    \"\"\"\n",
    "    tz = ZoneInfo(\"Europe/Zurich\")\n",
    "    now_local = pd.Timestamp.now(tz=tz).floor(\"h\")\n",
    "    start_local = now_local.normalize().replace(day=1)\n",
    "    yesterday_local = now_local.normalize() - pd.Timedelta(days=1)\n",
    "    return (\n",
    "        start_local.tz_convert(None),\n",
    "        now_local.tz_convert(None),\n",
    "        yesterday_local.tz_convert(None),\n",
    "    )\n",
    "\n",
    "def _offset_fixed_with_initial(\n",
    "    fixed_delta: pd.DataFrame,\n",
    "    init_map: dict[str, float],\n",
    "    accounts: list[str],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Turn per-period deltas into realized equity by adding SQL initial balances.\"\"\"\n",
    "    if fixed_delta.empty:\n",
    "        return fixed_delta\n",
    "    fixed = fixed_delta.copy()\n",
    "    for a in accounts:\n",
    "        if a in fixed.columns:\n",
    "            fixed[a] = fixed[a] + float(init_map.get(a, 0.0))\n",
    "    return fixed\n",
    "\n",
    "def build_metrics_payload(accounts: Sequence[str]) -> dict[str, object]:\n",
    "    accs = [a.strip().lower() for a in accounts if a.strip()]\n",
    "    start_day, today, _yesterday = _mtd_window_today()\n",
    "\n",
    "    # Initial balances (SQL only)\n",
    "    init_map: dict[str, float] = {}\n",
    "    for a in accs:\n",
    "        bal, _ts = nearest_balance_on_or_before(a, start_day)\n",
    "        init_map[a] = float(bal)\n",
    "\n",
    "    # Realized equity (SQL deltas + SQL initial), hourly through NOW\n",
    "    fixed_delta, _ = build_fixed_balances(accs, start_day, today)\n",
    "    fixed = _offset_fixed_with_initial(fixed_delta, init_map, accs)\n",
    "\n",
    "    # Returns blocks (MTD series-based) — series-level MTD% using levels\n",
    "    fixed_total = fixed.assign(total=fixed[accs].sum(axis=1)) if not fixed.empty else fixed\n",
    "    mtd_ret_realized = mtd_return(fixed_total) if not fixed_total.empty else {}\n",
    "    print(f\"mtd_ret_realized: {mtd_ret_realized}\")\n",
    "\n",
    "build_metrics_payload([\"fund2\", \"fund3\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afmonitor2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
